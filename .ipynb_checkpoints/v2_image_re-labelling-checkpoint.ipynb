{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e91ebdc-867e-4eff-8041-ed33a7eeca9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# image re-labelling code\n",
    "going over the images i have already labelled, and re-labelling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5cca462-16c9-4293-a7b5-380e8b25b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#from PIL import Image\n",
    "from glob import glob\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "from numba import jit\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f61af8f-1e67-4803-b7a7-d67a09d090f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/2ds_10000_8_dif.csv\n",
      "saving to /gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/2ds_10000_8_dif.csv\n",
      "number of images already labelled: 8619\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>number_label</th>\n",
       "      <th>2nd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1697685_23ch1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>669294_20ch0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>601343_19ch0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18058_26ch1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1261837_25ch0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name  number_label  2nd_label\n",
       "0  1697685_23ch1           1.0        1.0\n",
       "1   669294_20ch0           1.0        1.0\n",
       "2   601343_19ch0           1.0        1.0\n",
       "3    18058_26ch1           1.0        1.0\n",
       "4  1261837_25ch0           3.0        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## directory of set of images i would like to label + corresponding csv to populate\n",
    "folder_path = '/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/'\n",
    "# open csv quickly to check it is correct + in the format we expect\n",
    "csv_file_name = '2ds_10000_8_dif.csv'\n",
    "saving_csv_name = '2ds_10000_8_dif.csv'\n",
    "csv_full_path = os.path.join(folder_path,csv_file_name)\n",
    "full_save_csv_path = os.path.join(folder_path,saving_csv_name)\n",
    "csv_read_pd = pd.read_csv(csv_full_path)\n",
    "print(f'reading {csv_full_path}')\n",
    "print(f'saving to {full_save_csv_path}')\n",
    "n_images_done = csv_read_pd['2nd_label'].count()\n",
    "print(f'number of images already labelled: {n_images_done}')\n",
    "csv_read_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894c6ee4-e75c-4e88-a6db-5bb0419c0e23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncount_cp = csv_read_pd['number_label'].value_counts().get(11.0, 0)\\nprint(count_cp)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## updating the already labelled csv - make new column + saving in og place\n",
    "#csv_read_pd['2nd_label'] = np.nan\n",
    "#csv_read_pd\n",
    "#full_save_csv_path = os.path.join(folder_path,saving_csv_name)\n",
    "#csv_read_pd.to_csv(full_save_csv_path, index=False)\n",
    "\n",
    "## how many of each category\n",
    "'''\n",
    "count_cp = csv_read_pd['number_label'].value_counts().get(11.0, 0)\n",
    "print(count_cp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f452a-79a3-4f38-a654-7b328f6e9cb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# label things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f1b69a-3aad-411d-b2cc-69b5a6176d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_interest = 11 # between 1 to 9, or 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b53dc7-5ffb-4d25-a958-18c646110465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ds_10000_8_dif.csv saved!\n"
     ]
    }
   ],
   "source": [
    "# okay we are going to need a completly different approach for this\n",
    "def v2_saving_function(df,save_path):\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f'{saving_csv_name} saved!')\n",
    "    return df\n",
    "\n",
    "# make a list of index where these images are located\n",
    "interesting_idx = csv_read_pd.index[csv_read_pd['number_label'] == number_of_interest].tolist()\n",
    "\n",
    "for i in range(len(interesting_idx)):\n",
    "#for i in range(10):\n",
    "    idx = interesting_idx[i]\n",
    "    row = csv_read_pd.loc[idx]\n",
    "    image_name = row.iloc[0]\n",
    "    og_label = row.iloc[1]\n",
    "    new_label = row.iloc[2]\n",
    "\n",
    "    # I've already labelled it a second time\n",
    "    if not pd.isna(new_label):\n",
    "        continue\n",
    "\n",
    "    ## lets do the whole image labelling thing\n",
    "    else:\n",
    "        print(image_name)\n",
    "        im = Image.open(os.path.join(folder_path, image_name + '.png'))\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        while True: # loop will continue until a valid entry is passed\n",
    "            inp = input(\"Enter a label (0-9 or 11, or 'stop' to quit): \") ## label of image\n",
    "\n",
    "            ## if write 'stop' will stop labelling + save what has been done\n",
    "            if inp.lower() == 'stop':\n",
    "                print(\"Stopped labeling.\")\n",
    "                updated_df = v2_saving_function(csv_read_pd,full_save_csv_path)\n",
    "                raise SystemExit  # Exit gracefully\n",
    "            \n",
    "            try:\n",
    "                num = int(inp) # convert to number (corresponding to label)\n",
    "                if 0 <= num <= 11:  # Check if the number is in the valid range\n",
    "                    clear_output(wait=True) # get rid of image once you've labelled it\n",
    "                    csv_read_pd.loc[idx, '2nd_label'] = num ## as working in a df, we over-write the correct cell\n",
    "                    break  # Exit the loop if the input is valid\n",
    "                else:\n",
    "                    print(\"Error: Label must be between 0 and 11.\")\n",
    "            except ValueError: # if we don't input a number -> stop labelling, so will break\n",
    "                print(\"not words, what are you doing???\")\n",
    "        \n",
    "updated_df = v2_saving_function(csv_read_pd,full_save_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771238d-9be6-4649-aad8-f6cdfe12f8c6",
   "metadata": {},
   "source": [
    "## hide extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2fec95-e0d9-4d78-a8bf-cfcfabb8e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ds_10000_6.csv saved!\n"
     ]
    }
   ],
   "source": [
    "csv_read_pd['2nd_label'].value_counts().get(1.0, 0)\n",
    "#csv_read_pd['2nd_label'].count()\n",
    "#df.to_csv(csv_file_list[0], index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33386025-0b12-44f7-833a-762d359ad903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/users/esree/CNN_basics/save_progress/2ds_10000_8_dif.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## copy newly labelled csv to github too\n",
    "git_path = '/home/users/esree/CNN_basics/save_progress/'\n",
    "shutil.copy(full_save_csv_path, git_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b6ad6-36f5-4289-8e06-ec8874e249f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# csv overwrite current label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "323568b1-7e3a-4cc8-9c75-fb6612991111",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_csv = '2ds_10000.csv' ## original file\n",
    "new_csv = '2ds_10000_8_dif.csv' ## new labels - in second column, but not all are second labelled\n",
    "og_df = pd.read_csv(folder_path+og_csv)\n",
    "new_df = pd.read_csv(folder_path+new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "307666b8-3ad8-4d59-bb0d-b40580e448f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>number_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1697685_23ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>669294_20ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>601343_19ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18058_26ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1261837_25ch0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>387342_02ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>676765_19ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>159619_06ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2003638_23ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1569153_20ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  number_label\n",
       "0     1697685_23ch1           1.0\n",
       "1      669294_20ch0           1.0\n",
       "2      601343_19ch0           1.0\n",
       "3       18058_26ch1           1.0\n",
       "4     1261837_25ch0           3.0\n",
       "...             ...           ...\n",
       "9995   387342_02ch1           1.0\n",
       "9996   676765_19ch0           1.0\n",
       "9997   159619_06ch1           1.0\n",
       "9998  2003638_23ch0           1.0\n",
       "9999  1569153_20ch1           1.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combining og labels + new labels - replace old labels\n",
    "length_of_data = len(og_df['image_name'])\n",
    "name_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for idx in range(int(length_of_data)):\n",
    "    row = csv_read_pd.loc[idx]\n",
    "    image_name = row.iloc[0]\n",
    "    og_label = row.iloc[1]\n",
    "    new_label = row.iloc[2]\n",
    "    \n",
    "    name_lst.append(image_name)\n",
    "    if not pd.isna(new_label):\n",
    "        label_lst.append(new_label)\n",
    "    else:\n",
    "        label_lst.append(og_label)\n",
    "\n",
    "df_dic = {'image_name':name_lst,'number_label':label_lst}\n",
    "new_df = pd.DataFrame(df_dic)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ce7ddb-2e8b-4f3a-b3ce-b2fee668841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ds_10000_new.csv saved!\n"
     ]
    }
   ],
   "source": [
    "new_df['number_label'].count()\n",
    "saving_csv_name = '2ds_10000_new.csv'\n",
    "#saved_df = v2_saving_function(new_df,folder_path+saving_csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c974dd6-cb1d-46a9-b599-24648e5d618f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# group images together to download them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fee4944b-4292-4d10-9080-cf6ad1808647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/CP\n",
      "FA\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/FA\n",
      "Co\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/Co\n",
      "HPC\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/HPC\n",
      "CBC\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/CBC\n",
      "CA\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/CA\n",
      "CC\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/CC\n",
      "WD\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/WD\n",
      "DIF\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/DIF\n",
      "unknown\n",
      "/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/unknown\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/'\n",
    "csv_file_name = '2ds_10000_new.csv'\n",
    "csv_read_pd = pd.read_csv(folder_path+csv_file_name)\n",
    "\n",
    "category_dic = {'1.0':'CP','2.0':'FA','3.0':'Co','4.0':'HPC','6.0':'CBC','7.0':'CA','8.0':'CC','9.0':'WD','0.0':'DIF','11.0':'unknown'}\n",
    "category_dic_extra = {} # adding in path to loc \n",
    "for key in category_dic:\n",
    "    var_name = category_dic[key]\n",
    "    individ_cat_path = folder_path+var_name+'/'\n",
    "    category_dic_extra[key] = [var_name,individ_cat_path]\n",
    "\n",
    "'''\n",
    "## make bunch of directories with appropriate names\n",
    "category_names_lst = [category_dic[key] for key in category_dic] ## ayy make a list of category names from our dictionary values # newlist = [expression for item in iterable if condition == True]\n",
    "\n",
    "# make each name a folder\n",
    "for cat_name in category_names_lst:\n",
    "    path = folder_path+cat_name+'/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"{cat_name} created successfully!\")\n",
    "    else:\n",
    "        print(f\"{cat_name} already exists.\")\n",
    "'''\n",
    "\n",
    "\n",
    "length_of_data = len(csv_read_pd['image_name'])\n",
    "for idx in range(int(length_of_data/1000)):\n",
    "    row = csv_read_pd.loc[idx]\n",
    "    image_name = row.iloc[0]\n",
    "    label = row.iloc[1]\n",
    "    og_loc = folder_path+image_name+'.png'\n",
    "    new_loc = category_dic_extra[str(label)][1]\n",
    "    \n",
    "    shutil.copy(og_loc, new_loc)\n",
    "\n",
    "print('copying images finished')\n",
    "\n",
    "# zip up the folders with images in\n",
    "for key in category_dic_extra:\n",
    "    cat_folder = category_dic_extra[key][0]\n",
    "    folder_path_to_zip = category_dic_extra[key][1][:-1]\n",
    "    shutil.make_archive(folder_path_to_zip, 'zip',folder_path_to_zip) # as we are saving with same name but with .zip\n",
    "    print(f'{cat_folder} zipped!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a501754d-e2e5-416a-92ae-07e098d1eedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CP', 'FA', 'Co', 'HPC', 'CBC', 'CA', 'CC', 'WD', 'DIF', 'unknown']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f5970c5-5a37-4fb2-a974-8b8dd9ecbea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>number_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1697685_23ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>669294_20ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>601343_19ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18058_26ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1261837_25ch0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>484599_25ch0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1435287_23ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1710083_20ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2586247_25ch1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>299315_20ch0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name  number_label\n",
       "0  1697685_23ch1           1.0\n",
       "1   669294_20ch0           1.0\n",
       "2   601343_19ch0           1.0\n",
       "3    18058_26ch1           1.0\n",
       "4  1261837_25ch0           3.0\n",
       "5   484599_25ch0           2.0\n",
       "6  1435287_23ch0           1.0\n",
       "7  1710083_20ch0           1.0\n",
       "8  2586247_25ch1           1.0\n",
       "9   299315_20ch0           1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_read_pd[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623aff86-4815-4948-8c56-a54a65f82e12",
   "metadata": {},
   "source": [
    "# extract relevant particle stats of ones labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e8d56c-0da8-4d0e-8a07-3fdf8e6e87e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_2ds_stats = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/2ds/all_2ds.csv'\n",
    "path_labelled = '/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/2ds_10000_new_2nd.csv'\n",
    "\n",
    "full_ds_stats = pd.read_csv(path_2ds_stats)\n",
    "image_labelled_df = pd.read_csv(path_labelled)\n",
    "\n",
    "images_labelled_lst = list(image_labelled_df['image_name'])\n",
    "\n",
    "labelled_image_stats = full_ds_stats[full_ds_stats['name'].isin(images_labelled_lst)]\n",
    "\n",
    "\n",
    "## need to add new column - with the label on\n",
    "# not sure why 2 extra rows on df more than have been labelled??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f8f08-c29f-4ed0-a483-7069839db90a",
   "metadata": {},
   "source": [
    "## i have now discoved i have duplicate data, but i will have only extracted one of the images. but i don't know which one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdfca64-10d5-4a58-b49b-c554987253cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>slice_s_idx</th>\n",
       "      <th>slice_e_idx</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>ellipse_d_max</th>\n",
       "      <th>Euclidean_d_max</th>\n",
       "      <th>Feret_d_max</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>first_diode_trunc</th>\n",
       "      <th>last_diode_trunc</th>\n",
       "      <th>image_trunc</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>wind_w</th>\n",
       "      <th>pres</th>\n",
       "      <th>alt</th>\n",
       "      <th>temp</th>\n",
       "      <th>LWC</th>\n",
       "      <th>IWC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855825</th>\n",
       "      <td>2484896_25ch1</td>\n",
       "      <td>220725</td>\n",
       "      <td>2484896</td>\n",
       "      <td>2484914</td>\n",
       "      <td>19:37:49.125000000</td>\n",
       "      <td>19:37:49.125000000</td>\n",
       "      <td>217.905812</td>\n",
       "      <td>184.390889</td>\n",
       "      <td>196.468827</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.949269</td>\n",
       "      <td>-0.382931</td>\n",
       "      <td>380.90970</td>\n",
       "      <td>7979.3060</td>\n",
       "      <td>256.33566</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.284747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940222</th>\n",
       "      <td>47102_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47131</td>\n",
       "      <td>19:26:38.926000000</td>\n",
       "      <td>19:26:39.519000000</td>\n",
       "      <td>289.030963</td>\n",
       "      <td>318.904374</td>\n",
       "      <td>328.024389</td>\n",
       "      <td>50300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172358</td>\n",
       "      <td>-4.348890</td>\n",
       "      <td>410.21915</td>\n",
       "      <td>7428.8936</td>\n",
       "      <td>257.82507</td>\n",
       "      <td>0.204330</td>\n",
       "      <td>0.008787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name    date  slice_s_idx  slice_e_idx          start_time  \\\n",
       "855825  2484896_25ch1  220725      2484896      2484914  19:37:49.125000000   \n",
       "940222    47102_07ch1  220807        47102        47131  19:26:38.926000000   \n",
       "\n",
       "                  end_time  ellipse_d_max  Euclidean_d_max  Feret_d_max  \\\n",
       "855825  19:37:49.125000000     217.905812       184.390889   196.468827   \n",
       "940222  19:26:39.519000000     289.030963       318.904374   328.024389   \n",
       "\n",
       "           area  ...  first_diode_trunc  last_diode_trunc image_trunc  \\\n",
       "855825   5000.0  ...                  0                 0           0   \n",
       "940222  50300.0  ...                  0                 0           0   \n",
       "\n",
       "        aspect_ratio    wind_w       pres        alt       temp       LWC  \\\n",
       "855825      3.949269 -0.382931  380.90970  7979.3060  256.33566  0.006337   \n",
       "940222      1.172358 -4.348890  410.21915  7428.8936  257.82507  0.204330   \n",
       "\n",
       "             IWC  \n",
       "855825  0.284747  \n",
       "940222  0.008787  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_mask = labelled_image_stats.duplicated(subset=['name'])\n",
    "duplicates_df = labelled_image_stats[duplicates_mask]\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861e70a5-c261-427a-808d-8f3ef82f4209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>slice_s_idx</th>\n",
       "      <th>slice_e_idx</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>ellipse_d_max</th>\n",
       "      <th>Euclidean_d_max</th>\n",
       "      <th>Feret_d_max</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>first_diode_trunc</th>\n",
       "      <th>last_diode_trunc</th>\n",
       "      <th>image_trunc</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>wind_w</th>\n",
       "      <th>pres</th>\n",
       "      <th>alt</th>\n",
       "      <th>temp</th>\n",
       "      <th>LWC</th>\n",
       "      <th>IWC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923312</th>\n",
       "      <td>47102_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47126</td>\n",
       "      <td>16:37:00.357000000</td>\n",
       "      <td>16:37:03.899000000</td>\n",
       "      <td>273.403521</td>\n",
       "      <td>282.842712</td>\n",
       "      <td>290.688837</td>\n",
       "      <td>41600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.283139</td>\n",
       "      <td>0.561548</td>\n",
       "      <td>446.08530</td>\n",
       "      <td>6787.3706</td>\n",
       "      <td>261.83868</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940222</th>\n",
       "      <td>47102_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47131</td>\n",
       "      <td>19:26:38.926000000</td>\n",
       "      <td>19:26:39.519000000</td>\n",
       "      <td>289.030963</td>\n",
       "      <td>318.904374</td>\n",
       "      <td>328.024389</td>\n",
       "      <td>50300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172358</td>\n",
       "      <td>-4.348890</td>\n",
       "      <td>410.21915</td>\n",
       "      <td>7428.8936</td>\n",
       "      <td>257.82507</td>\n",
       "      <td>0.204330</td>\n",
       "      <td>0.008787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name    date  slice_s_idx  slice_e_idx          start_time  \\\n",
       "923312  47102_07ch1  220807        47102        47126  16:37:00.357000000   \n",
       "940222  47102_07ch1  220807        47102        47131  19:26:38.926000000   \n",
       "\n",
       "                  end_time  ellipse_d_max  Euclidean_d_max  Feret_d_max  \\\n",
       "923312  16:37:03.899000000     273.403521       282.842712   290.688837   \n",
       "940222  19:26:39.519000000     289.030963       318.904374   328.024389   \n",
       "\n",
       "           area  ...  first_diode_trunc  last_diode_trunc image_trunc  \\\n",
       "923312  41600.0  ...                 18                 0           0   \n",
       "940222  50300.0  ...                  0                 0           0   \n",
       "\n",
       "        aspect_ratio    wind_w       pres        alt       temp       LWC  \\\n",
       "923312      1.283139  0.561548  446.08530  6787.3706  261.83868  0.001382   \n",
       "940222      1.172358 -4.348890  410.21915  7428.8936  257.82507  0.204330   \n",
       "\n",
       "             IWC  \n",
       "923312  0.000019  \n",
       "940222  0.008787  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_1 = labelled_image_stats[labelled_image_stats['name'] == '2484896_25ch1']\n",
    "duplicate_2 = labelled_image_stats[labelled_image_stats['name'] == '47102_07ch1']\n",
    "\n",
    "duplicate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e895aef-6cf4-4d6c-a9da-14cc76d2663b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3767629083.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    for\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "new_csv = '/gws/nopw/j04/dcmex/users/ezriab/image_labelling/2ds_10000_sample/2ds_10000_new_2nd.csv'\n",
    "full_ds_stats = pd.read_csv(new_csv)\n",
    " \n",
    "\n",
    "full_ds_stats['note'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fafa18e6-f67e-4f95-b968-c39baab51b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>slice_s_idx</th>\n",
       "      <th>slice_e_idx</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>ellipse_d_max</th>\n",
       "      <th>Euclidean_d_max</th>\n",
       "      <th>Feret_d_max</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>first_diode_trunc</th>\n",
       "      <th>last_diode_trunc</th>\n",
       "      <th>image_trunc</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>wind_w</th>\n",
       "      <th>pres</th>\n",
       "      <th>alt</th>\n",
       "      <th>temp</th>\n",
       "      <th>LWC</th>\n",
       "      <th>IWC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>94298_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>94298</td>\n",
       "      <td>94332</td>\n",
       "      <td>18:53:04.977000000</td>\n",
       "      <td>18:53:04.977000000</td>\n",
       "      <td>349.710133</td>\n",
       "      <td>392.045916</td>\n",
       "      <td>402.243707</td>\n",
       "      <td>71300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.219161</td>\n",
       "      <td>-2.043195</td>\n",
       "      <td>400.87717</td>\n",
       "      <td>7644.9404</td>\n",
       "      <td>257.90890</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.076399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>94298_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>94298</td>\n",
       "      <td>94311</td>\n",
       "      <td>18:53:04.977000000</td>\n",
       "      <td>18:53:04.977000000</td>\n",
       "      <td>146.839578</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>140.356688</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.089049</td>\n",
       "      <td>-2.043195</td>\n",
       "      <td>400.87717</td>\n",
       "      <td>7644.9404</td>\n",
       "      <td>257.90890</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.076399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>226470_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>226470</td>\n",
       "      <td>226482</td>\n",
       "      <td>18:56:50.694000000</td>\n",
       "      <td>18:56:50.694000000</td>\n",
       "      <td>152.272582</td>\n",
       "      <td>126.491106</td>\n",
       "      <td>143.178211</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.395385</td>\n",
       "      <td>-2.762317</td>\n",
       "      <td>388.69946</td>\n",
       "      <td>7885.3310</td>\n",
       "      <td>255.70236</td>\n",
       "      <td>0.162223</td>\n",
       "      <td>0.334879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>226470_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>226470</td>\n",
       "      <td>226483</td>\n",
       "      <td>18:56:50.694000000</td>\n",
       "      <td>18:56:50.694000000</td>\n",
       "      <td>174.590712</td>\n",
       "      <td>172.046505</td>\n",
       "      <td>186.010752</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533949</td>\n",
       "      <td>-2.762317</td>\n",
       "      <td>388.69946</td>\n",
       "      <td>7885.3310</td>\n",
       "      <td>255.70236</td>\n",
       "      <td>0.162223</td>\n",
       "      <td>0.334879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8595</th>\n",
       "      <td>230869_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>230869</td>\n",
       "      <td>230879</td>\n",
       "      <td>18:56:50.772000000</td>\n",
       "      <td>18:56:50.772000000</td>\n",
       "      <td>135.556367</td>\n",
       "      <td>144.222051</td>\n",
       "      <td>152.643375</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.263412</td>\n",
       "      <td>-2.762317</td>\n",
       "      <td>388.69946</td>\n",
       "      <td>7885.3310</td>\n",
       "      <td>255.70236</td>\n",
       "      <td>0.186962</td>\n",
       "      <td>0.442953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932424</th>\n",
       "      <td>315316_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>315316</td>\n",
       "      <td>315356</td>\n",
       "      <td>17:34:41.285000000</td>\n",
       "      <td>17:34:41.300000000</td>\n",
       "      <td>417.369190</td>\n",
       "      <td>512.249939</td>\n",
       "      <td>520.096145</td>\n",
       "      <td>88900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.315120</td>\n",
       "      <td>-1.812491</td>\n",
       "      <td>416.33398</td>\n",
       "      <td>7310.0000</td>\n",
       "      <td>258.07930</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939967</th>\n",
       "      <td>18539_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>18539</td>\n",
       "      <td>18595</td>\n",
       "      <td>19:18:02.117000000</td>\n",
       "      <td>19:18:02.117000000</td>\n",
       "      <td>579.097229</td>\n",
       "      <td>676.239603</td>\n",
       "      <td>688.186021</td>\n",
       "      <td>146400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.589710</td>\n",
       "      <td>0.090431</td>\n",
       "      <td>431.38864</td>\n",
       "      <td>7046.8150</td>\n",
       "      <td>260.83000</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940010</th>\n",
       "      <td>34578_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>34578</td>\n",
       "      <td>34691</td>\n",
       "      <td>19:20:07.116000000</td>\n",
       "      <td>19:20:40.110000000</td>\n",
       "      <td>977.017933</td>\n",
       "      <td>1136.353818</td>\n",
       "      <td>1146.298390</td>\n",
       "      <td>223500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>3.120222</td>\n",
       "      <td>-3.798381</td>\n",
       "      <td>417.02188</td>\n",
       "      <td>7294.1480</td>\n",
       "      <td>259.73830</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940011</th>\n",
       "      <td>34578_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>34578</td>\n",
       "      <td>34603</td>\n",
       "      <td>19:20:07.116000000</td>\n",
       "      <td>19:20:40.110000000</td>\n",
       "      <td>258.089121</td>\n",
       "      <td>259.615100</td>\n",
       "      <td>269.258240</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.987685</td>\n",
       "      <td>-3.798381</td>\n",
       "      <td>417.02188</td>\n",
       "      <td>7294.1480</td>\n",
       "      <td>259.73830</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940222</th>\n",
       "      <td>47102_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47131</td>\n",
       "      <td>19:26:38.926000000</td>\n",
       "      <td>19:26:39.519000000</td>\n",
       "      <td>289.030963</td>\n",
       "      <td>318.904374</td>\n",
       "      <td>328.024389</td>\n",
       "      <td>50300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172358</td>\n",
       "      <td>-4.348890</td>\n",
       "      <td>410.21915</td>\n",
       "      <td>7428.8936</td>\n",
       "      <td>257.82507</td>\n",
       "      <td>0.204330</td>\n",
       "      <td>0.008787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name    date  slice_s_idx  slice_e_idx          start_time  \\\n",
       "3327     94298_19ch0  220719        94298        94332  18:53:04.977000000   \n",
       "3328     94298_19ch0  220719        94298        94311  18:53:04.977000000   \n",
       "8430    226470_19ch0  220719       226470       226482  18:56:50.694000000   \n",
       "8431    226470_19ch0  220719       226470       226483  18:56:50.694000000   \n",
       "8595    230869_19ch0  220719       230869       230879  18:56:50.772000000   \n",
       "...              ...     ...          ...          ...                 ...   \n",
       "932424  315316_07ch1  220807       315316       315356  17:34:41.285000000   \n",
       "939967   18539_07ch1  220807        18539        18595  19:18:02.117000000   \n",
       "940010   34578_07ch1  220807        34578        34691  19:20:07.116000000   \n",
       "940011   34578_07ch1  220807        34578        34603  19:20:07.116000000   \n",
       "940222   47102_07ch1  220807        47102        47131  19:26:38.926000000   \n",
       "\n",
       "                  end_time  ellipse_d_max  Euclidean_d_max  Feret_d_max  \\\n",
       "3327    18:53:04.977000000     349.710133       392.045916   402.243707   \n",
       "3328    18:53:04.977000000     146.839578       130.000000   140.356688   \n",
       "8430    18:56:50.694000000     152.272582       126.491106   143.178211   \n",
       "8431    18:56:50.694000000     174.590712       172.046505   186.010752   \n",
       "8595    18:56:50.772000000     135.556367       144.222051   152.643375   \n",
       "...                    ...            ...              ...          ...   \n",
       "932424  17:34:41.300000000     417.369190       512.249939   520.096145   \n",
       "939967  19:18:02.117000000     579.097229       676.239603   688.186021   \n",
       "940010  19:20:40.110000000     977.017933      1136.353818  1146.298390   \n",
       "940011  19:20:40.110000000     258.089121       259.615100   269.258240   \n",
       "940222  19:26:39.519000000     289.030963       318.904374   328.024389   \n",
       "\n",
       "            area  ...  first_diode_trunc  last_diode_trunc image_trunc  \\\n",
       "3327     71300.0  ...                 25                 0           0   \n",
       "3328      4400.0  ...                  0                 0           0   \n",
       "8430      4200.0  ...                  0                 0           0   \n",
       "8431     13000.0  ...                  0                 0           0   \n",
       "8595      8000.0  ...                  0                 0           0   \n",
       "...          ...  ...                ...               ...         ...   \n",
       "932424   88900.0  ...                  0                33           0   \n",
       "939967  146400.0  ...                  6                 0           0   \n",
       "940010  223500.0  ...                  0                83           0   \n",
       "940011    8200.0  ...                  0                17           0   \n",
       "940222   50300.0  ...                  0                 0           0   \n",
       "\n",
       "        aspect_ratio    wind_w       pres        alt       temp       LWC  \\\n",
       "3327        1.219161 -2.043195  400.87717  7644.9404  257.90890  0.032683   \n",
       "3328        3.089049 -2.043195  400.87717  7644.9404  257.90890  0.032683   \n",
       "8430        3.395385 -2.762317  388.69946  7885.3310  255.70236  0.162223   \n",
       "8431        1.533949 -2.762317  388.69946  7885.3310  255.70236  0.162223   \n",
       "8595        1.263412 -2.762317  388.69946  7885.3310  255.70236  0.186962   \n",
       "...              ...       ...        ...        ...        ...       ...   \n",
       "932424      1.315120 -1.812491  416.33398  7310.0000  258.07930  0.019274   \n",
       "939967      1.589710  0.090431  431.38864  7046.8150  260.83000  0.000063   \n",
       "940010      3.120222 -3.798381  417.02188  7294.1480  259.73830  0.000284   \n",
       "940011      4.987685 -3.798381  417.02188  7294.1480  259.73830  0.000284   \n",
       "940222      1.172358 -4.348890  410.21915  7428.8936  257.82507  0.204330   \n",
       "\n",
       "             IWC  \n",
       "3327    0.076399  \n",
       "3328    0.076399  \n",
       "8430    0.334879  \n",
       "8431    0.334879  \n",
       "8595    0.442953  \n",
       "...          ...  \n",
       "932424  0.000000  \n",
       "939967  0.000000  \n",
       "940010  0.000012  \n",
       "940011  0.000012  \n",
       "940222  0.008787  \n",
       "\n",
       "[295 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "full_duplicates_mask = full_ds_stats.duplicated(subset=['name'])\n",
    "full_duplicates_df = full_ds_stats[full_duplicates_mask]\n",
    "full_duplicates_df\n",
    "\n",
    "list_of_duplicates = list(full_duplicates_df['name'])\n",
    "double_duplicates_df = full_ds_stats[full_ds_stats['name'].isin(list_of_duplicates)]\n",
    "\n",
    "double_duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29afc7a-715b-46a3-a04c-a356b3016dd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n",
      "yep\n"
     ]
    }
   ],
   "source": [
    "length_of_data = len(full_ds_stats['image_name'])\n",
    "\n",
    "for idx in range(length_of_data):\n",
    "    row = full_ds_stats.loc[idx]\n",
    "    image_name = row.iloc[0]\n",
    "    label = row.iloc[1]\n",
    "    note = row.iloc[2]\n",
    "    #og_loc = folder_path+image_name+'.png'\n",
    "    #new_loc = category_dic_extra[str(label)][1]\n",
    "    if not note != 'a':\n",
    "        print('yep')\n",
    "\t    #shutil.copy(og_loc, new_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87c2f98e-edbe-4338-b4a7-8f153696fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_duplicates_df\n",
    "\n",
    "#double_duplicates_df.to_csv('duplicates_df.csv', index=False)\n",
    "reduced_duplicates = full_duplicates_df[:10]\n",
    "reduced_duplicates.to_csv('/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/red_duplicates_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049f2b3-deca-4a6a-aeb3-9e5680a86383",
   "metadata": {},
   "source": [
    "## fixing that because i am stupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6282e85a-0312-4a9a-a822-79036b502bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.special import gamma\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import h5py ####\n",
    "from PIL import Image\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "from scipy.ndimage import convolve, label\n",
    "from skimage.measure import regionprops, find_contours\n",
    "from scipy.spatial import ConvexHull, distance_matrix\n",
    "from scipy.spatial.distance import pdist\n",
    "from skimage.morphology import remove_small_holes ## remove holes <3\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage import measure\n",
    "import tensorflow as tf\n",
    "\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ac1e3ad-693a-4ca1-9c90-4798d8c10959",
   "metadata": {},
   "outputs": [],
   "source": [
    "## og functions / things to make script run smoothly\n",
    "## setting thresholds / res for attaining good particle final images\n",
    "fill_hole_threshold = 5 # max number pixels contained within particle that is filled in\n",
    "\n",
    "minimum_area = 20 # very quick metric to stop the processing of particles with area < 15 pixels\n",
    "desired_image_size = 200 \n",
    "pixel_resolution = 10 # mu for 2DS // need to be 150 for hvps\n",
    "length_threshold = 100 ## 100 mu for 2ds // 1500 mu for hvps\n",
    "\n",
    "def stats_description(bw_crystal, fill_hole_thresh):\n",
    "    #take binary image, fill in small holes and returns object containing stats about crystal\n",
    "    \n",
    "    filled_particle = remove_small_holes(bw_crystal.image, area_threshold=fill_hole_thresh) # fill in voids within binary image - better estimation of stats # may need to be altered\n",
    "       \n",
    "    if filled_particle.shape[0] < 2 or filled_particle.shape[1] < 2:\n",
    "        return filled_particle, None\n",
    "        \n",
    "    contours = measure.find_contours(filled_particle, 0.5)\n",
    "    if contours:\n",
    "        contour = max(contours, key=lambda x: x.shape[0])  # Sort contours by area (largest first) and select the largest contour\n",
    "        \n",
    "        labeled_image = measure.label(filled_particle)  # Label the image based on the threshold\n",
    "        region = measure.regionprops(labeled_image)[0]  # Assumes largest labeled region corresponds to largest contour\n",
    "        \n",
    "        return filled_particle, region\n",
    "    else:\n",
    "        return filled_particle, None\n",
    "\n",
    "\n",
    "## function to calculate truncation of particle\n",
    "@jit(nopython=True) # Enables full optimization by numba\n",
    "def calc_truncation(particle_coords):\n",
    "    ## so much simpler, looking at list of coordinates making up a particle, then summing ones in 0 and 127 row - i.e. first + last diode\n",
    "    lst_first_diode = [coord for coord in particle_coords if coord[0] == 0]\n",
    "    lst_last_diode = [coord for coord in particle_coords if coord[0] == 127]\n",
    "\n",
    "    n_top = len(lst_first_diode)\n",
    "    n_bottom = len(lst_last_diode)\n",
    "\n",
    "    return n_top, n_bottom # number pixels touching top / bottom respectively\n",
    "## \n",
    "\n",
    "###  set up dataframe, used to extract from raw h5 file + has stats about the particle\n",
    "columns = [\n",
    "    \"name\",\n",
    "    \"date\",\n",
    "    \"slice_s_idx\",\n",
    "    \"slice_e_idx\",\n",
    "    #\"start_time\", #hh:mm:ss \n",
    "    #\"end_time\", #hh:mm:ss \n",
    "    \"ellipse_d_max\", # um\n",
    "    #\"ellipse_d_min\", # um\n",
    "    \"Euclidean_d_max\", # um\n",
    "    \"Feret_d_max\", # um\n",
    "    \"area\", # um2\n",
    "    \"perimeter\", # um\n",
    "    \"circularity\",\n",
    "    \"probe\",\n",
    "    \"first_diode_trunc\",\n",
    "    \"last_diode_trunc\",\n",
    "    \"image_trunc\",\n",
    "    \"aspect_ratio\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8f1d28d-60ef-4e65-82ea-bebd28d0cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    ch0\n",
      "13    ch0\n",
      "Name: probe, dtype: object\n",
      "ch0\n"
     ]
    }
   ],
   "source": [
    "# hopefully \n",
    "dup_csv_pth = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/duplicates_df.csv'\n",
    "dup_df = pd.read_csv(dup_csv_pth)\n",
    "\n",
    "#dup_df.sort_values(by=['name'])\n",
    "#dup_df\n",
    "\n",
    "duplicates_mask = dup_df.duplicated(subset=['name'])\n",
    "one_dup_df = dup_df[duplicates_mask]\n",
    "dup_name_lst = list(one_dup_df['name']) # list of 1 name of all the duplicates\n",
    "row = dup_df[dup_df['name'] == dup_name_lst[6]] ## call out the specif rows which correspond to that name\n",
    "#row_idx = list(row.index) ## can get specif index of rows selected\n",
    "#for particle in row:\n",
    "#    print(particle)\n",
    "#row['name']\n",
    "var = 'probe'\n",
    "print(row[var])\n",
    "print(max(row[var].values)) ## this is how we can call out the max values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c58577d2-8f3e-4e00-8a0d-d872e9dac72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "94298 94332\n",
      "19\n",
      "226470 226483\n",
      "19\n",
      "230869 230879\n",
      "19\n",
      "235921 235938\n",
      "19\n",
      "249985 250002\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    row = dup_df[dup_df['name'] == dup_name_lst[i]] # all rows with same name\n",
    "    image_name = max(row['name'].values)\n",
    "    date = str(max(row['date'].values))\n",
    "    start_idx = max(row['slice_s_idx'].values)\n",
    "    end_idx = max(row['slice_e_idx'].values)\n",
    "    probe = max(row['probe'].values)\n",
    "    date_day = max(row[var].values)\n",
    "    date_day = date[-2:]\n",
    "\n",
    "    #print(row)\n",
    "    print(date_day)\n",
    "    print(f'{start_idx} {end_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "683d1065-9e89-4789-a18d-43b0bcbfc12f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_535/2617334597.py:112: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  particle_df = pd.concat([particle_df, one_particle_data_df], ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m             h5_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;66;03m#print(one_particle_data)\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m             one_particle_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mone_particle_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m             particle_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([particle_df, one_particle_data_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    114\u001b[0m particle_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_loc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mupdated_duplicates.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)        \n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/internals/construction.py:945\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m--> 945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents, columns\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/internals/construction.py:1070\u001b[0m, in \u001b[0;36mconvert_object_array\u001b[0;34m(content, dtype, dtype_backend, coerce_float)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1070\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/internals/construction.py:1070\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1070\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/pandas/core/internals/construction.py:1030\u001b[0m, in \u001b[0;36mconvert_object_array.<locals>.convert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(arr):\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1030\u001b[0m         arr \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m            \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtry_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;66;03m# Notes on cases that get here 2023-02-15\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m         \u001b[38;5;66;03m# 1) we DO get here when arr is all Timestamps and dtype=None\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# 2) disabling this doesn't break the world, so this must be\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;66;03m#    getting caught at a higher level\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;66;03m# 3) passing convert_non_numeric to maybe_convert_objects get this right\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;66;03m# 4) convert_non_numeric?\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## first attempt at fixing - just looping through rows wasnt working\n",
    "#dup_csv_pth = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/red_duplicates_df.csv'\n",
    "dup_csv_pth = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/duplicates_df.csv'\n",
    "save_loc = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/'\n",
    "\n",
    "base_h5_pth = '/gws/nopw/j04/dcmex/users/ezriab/raw_h5/2ds/'\n",
    "\n",
    "particle_df = pd.DataFrame(columns=columns)\n",
    "with open(dup_csv_pth, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    header = next(csv_reader)  # Read the header row\n",
    "    # loop through each row\n",
    "    for row in csv_reader:\n",
    "        image_name = row[0]\n",
    "        date = row[1] \n",
    "        start_idx = row[2]\n",
    "        end_idx = row[3]\n",
    "        probe = row[12]\n",
    "        date_day = date[-2:]\n",
    "        \n",
    "        h5_of_interest = [] ## some have multiple files associated with each date\n",
    "        list_h5_files = glob(base_h5_pth+probe+'/'+'*.h5')\n",
    "        for file in list_h5_files:\n",
    "            if date in file:\n",
    "                h5_of_interest.append(file)\n",
    "\n",
    "        for h5_path in h5_of_interest:\n",
    "            h5_file = h5py.File(h5_path,'r')\n",
    "\n",
    "            try:\n",
    "                h5_image = h5_file['ImageData']\n",
    "                h5_time = h5_file['ImageTimes']\n",
    "            except KeyError as e:\n",
    "                print(f\"Dataset missing in file: {file}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            one_crystal = h5_file['ImageData'][:,int(start_idx)-2:int(end_idx)+2] # extract 1 crystal\n",
    "            #plt.imshow(one_crystal, cmap='gray')\n",
    "            binary_image = (one_crystal == 0) \n",
    "            labeled_image, num_features = label(binary_image)\n",
    "            try:\n",
    "                props = regionprops(labeled_image)\n",
    "            except ValueError as e:\n",
    "                print('something has gone wrong')\n",
    "                continue\n",
    "                \n",
    "            for particle in props:\n",
    "                if particle.area >= minimum_area:\n",
    "                    filled_part, spec_region = stats_description(particle,fill_hole_threshold)\n",
    "                    if spec_region:\n",
    "                        aspect_ratio_value = spec_region.major_axis_length / spec_region.minor_axis_length\n",
    "                        coords = particle.coords # basically gives coords of each point of interest [row,column]\n",
    "                        distances = pdist(coords)\n",
    "                        euclidean_dim = np.max(distances)\n",
    "\n",
    "                        if euclidean_dim * pixel_resolution >= length_threshold:\n",
    "                                \n",
    "                            ## basic info\n",
    "                            x_values = np.unique(coords[:, 1])\n",
    "                            #s_idx = int(selected_pix_sum[i] + x_values[0])\n",
    "                            #e_idx = int(selected_pix_sum[i] + x_values[-1])\n",
    "            \n",
    "                            ## truncation calc\n",
    "                            # cnn - in final pic size, particle may be truncated if very long, this tells us how many pixels may be cut off \n",
    "                            image_trunc = x_values[-1] - desired_image_size \n",
    "                            if image_trunc < 0:\n",
    "                                image_trunc = 0\n",
    "                            # normal trunc calculation - on actual probe\n",
    "                            first_diode, last_diode = calc_truncation(coords)\n",
    "                            \n",
    "                            ## using circularity calculation from Crosier et al. 2011\n",
    "                            circularity_calc = np.divide((spec_region.perimeter**2),(4*np.pi*spec_region.area))\n",
    "                            particle_name = f'{start_idx}_{particle.label}_{date_day}{probe}'\n",
    "                            \n",
    "                            # nice way of saving data - lenth + measurements are correct in microns\n",
    "                            one_particle_data = {\n",
    "                                    #\"image_index\": image_index,\n",
    "                                    \"name\": particle_name,\n",
    "                                    \"date\" : date,\n",
    "                                    \"slice_s_idx\": start_idx,\n",
    "                                    \"slice_e_idx\": end_idx,\n",
    "                                    #\"start_time\": str(selected_utc_time[i].values).split('T')[1], # more friendly time\n",
    "                                    #\"end_time\": str(selected_utc_time[i+1].values).split('T')[1], # more friendly time\n",
    "                                    \"ellipse_d_max\": spec_region.major_axis_length * pixel_resolution, ## d_max (equivalent ellipse)\n",
    "                                    #\"ellipse_d_min\": spec_region.minor_axis_length * pixel_resolution, ## d_min (equivalent ellipse)\n",
    "                                    \"Euclidean_d_max\": euclidean_dim * pixel_resolution,\n",
    "                                    \"Feret_d_max\":spec_region.feret_diameter_max * pixel_resolution,\n",
    "                                    \"area\": (spec_region.area * (pixel_resolution**2)),\n",
    "                                    \"perimeter\": (spec_region.perimeter * pixel_resolution),\n",
    "                                    \"circularity\": circularity_calc,\n",
    "                                    \"probe\": probe,\n",
    "                                    \"first_diode_trunc\": first_diode,\n",
    "                                    \"last_diode_trunc\": last_diode,\n",
    "                                    \"image_trunc\": image_trunc,\n",
    "                                    \"aspect_ratio\": aspect_ratio_value  \n",
    "                                    }\n",
    "\n",
    "                            filled_part = filled_part.astype(np.float32) ## convert to float 0 and 1s\n",
    "                            filled_part = np.expand_dims(filled_part, axis=-1) ## add extra dimention - this is for adding padding\n",
    "            \n",
    "                            imagex = tf.image.resize_with_crop_or_pad(filled_part, desired_image_size, desired_image_size)\n",
    "                            ## save image\n",
    "                            # Remove the extra dimension if needed\n",
    "                            image_np = imagex.numpy().squeeze()\n",
    "                            #plt.imshow(image_np, cmap='gray')\n",
    "                            plt.imsave(f'{save_loc}{particle_name}.png', image_np, cmap=\"gray\")\n",
    "                            \n",
    "\n",
    "            h5_file.close()\n",
    "            #print(one_particle_data)\n",
    "            one_particle_data_df = pd.DataFrame([one_particle_data])\n",
    "            particle_df = pd.concat([particle_df, one_particle_data_df], ignore_index=True)\n",
    "\n",
    "particle_df.to_csv(f'{save_loc}updated_duplicates.csv', index=False)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fa8d179-5a7a-4bb4-b2f6-a75c8c2789e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (truncated file: eof = 13631488, sblock->base_addr = 0, stored_eof = 16877012)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m         h5_of_interest\u001b[38;5;241m.\u001b[39mappend(file)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h5_path \u001b[38;5;129;01min\u001b[39;00m h5_of_interest:\n\u001b[0;32m---> 49\u001b[0m     h5_file \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         h5_image \u001b[38;5;241m=\u001b[39m h5_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageData\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to synchronously open file (truncated file: eof = 13631488, sblock->base_addr = 0, stored_eof = 16877012)"
     ]
    }
   ],
   "source": [
    "## second go - locate name pairs, then use the max end index \n",
    "#dup_csv_pth = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/red_duplicates_df.csv'\n",
    "dup_csv_pth = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/duplicates_df.csv'\n",
    "save_loc = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/'\n",
    "\n",
    "base_h5_pth = '/gws/nopw/j04/dcmex/users/ezriab/raw_h5/2ds/'\n",
    "particle_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "######## NEW ###########\n",
    "dup_df = pd.read_csv(dup_csv_pth)\n",
    "duplicates_mask = dup_df.duplicated(subset=['name'])\n",
    "one_dup_df = dup_df[duplicates_mask]\n",
    "dup_name_lst = list(one_dup_df['name']) # list of 1 name of all the duplicates\n",
    "######################\n",
    "\n",
    "'''\n",
    "with open(dup_csv_pth, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    header = next(csv_reader)  # Read the header row\n",
    "    # loop through each row\n",
    "    for row in csv_reader:\n",
    "        image_name = row[0]\n",
    "        date = row[1] \n",
    "        start_idx = row[2]\n",
    "        end_idx = row[3]\n",
    "        probe = row[12]\n",
    "        date_day = date[-2:]\n",
    "'''\n",
    "    ######## NEW ###########\n",
    "for i in range(len(dup_name_lst)):\n",
    "    row = dup_df[dup_df['name'] == dup_name_lst[i]] # all rows with same name\n",
    "    image_name = max(row['name'].values)\n",
    "    date = str(max(row['date'].values))\n",
    "    start_idx = max(row['slice_s_idx'].values)\n",
    "    end_idx = max(row['slice_e_idx'].values)\n",
    "    probe = max(row['probe'].values)\n",
    "    date_day = max(row[var].values)\n",
    "    date_day = date[-2:]\n",
    "\n",
    "    ########################\n",
    "        \n",
    "    h5_of_interest = [] ## some have multiple files associated with each date\n",
    "    list_h5_files = glob(base_h5_pth+probe+'/'+'*.h5')\n",
    "    for file in list_h5_files:\n",
    "        if date in file:\n",
    "            h5_of_interest.append(file)\n",
    "\n",
    "    for h5_path in h5_of_interest:\n",
    "        h5_file = h5py.File(h5_path,'r')\n",
    "\n",
    "        try:\n",
    "            h5_image = h5_file['ImageData']\n",
    "            h5_time = h5_file['ImageTimes']\n",
    "        except KeyError as e:\n",
    "            print(f\"Dataset missing in file: {file}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        one_crystal = h5_file['ImageData'][:,int(start_idx)-3:int(end_idx)+3] # extract 1 crystal\n",
    "        #plt.imshow(one_crystal, cmap='gray')\n",
    "        binary_image = (one_crystal == 0) \n",
    "        labeled_image, num_features = label(binary_image)\n",
    "        try:\n",
    "            props = regionprops(labeled_image)\n",
    "        except ValueError as e:\n",
    "            print('something has gone wrong')\n",
    "            continue\n",
    "            \n",
    "        for particle in props:\n",
    "            if particle.area >= minimum_area:\n",
    "                filled_part, spec_region = stats_description(particle,fill_hole_threshold)\n",
    "                if spec_region:\n",
    "                    aspect_ratio_value = spec_region.major_axis_length / spec_region.minor_axis_length\n",
    "                    coords = particle.coords # basically gives coords of each point of interest [row,column]\n",
    "                    distances = pdist(coords)\n",
    "                    euclidean_dim = np.max(distances)\n",
    "\n",
    "                    if euclidean_dim * pixel_resolution >= length_threshold:\n",
    "                            \n",
    "                        ## basic info\n",
    "                        x_values = np.unique(coords[:, 1])\n",
    "                        e_idx = start_idx+x_values[-1]\n",
    "                        #s_idx = int(selected_pix_sum[i] + x_values[0])\n",
    "                        #e_idx = int(selected_pix_sum[i] + x_values[-1])\n",
    "        \n",
    "                        ## truncation calc\n",
    "                        # cnn - in final pic size, particle may be truncated if very long, this tells us how many pixels may be cut off \n",
    "                        image_trunc = x_values[-1] - desired_image_size \n",
    "                        if image_trunc < 0:\n",
    "                            image_trunc = 0\n",
    "                        # normal trunc calculation - on actual probe\n",
    "                        first_diode, last_diode = calc_truncation(coords)\n",
    "                        \n",
    "                        ## using circularity calculation from Crosier et al. 2011\n",
    "                        circularity_calc = np.divide((spec_region.perimeter**2),(4*np.pi*spec_region.area))\n",
    "                        particle_name = f'{start_idx}_{particle.label}_{date_day}{probe}'\n",
    "                        \n",
    "                        # nice way of saving data - lenth + measurements are correct in microns\n",
    "                        one_particle_data = {\n",
    "                                #\"image_index\": image_index,\n",
    "                                \"name\": particle_name,\n",
    "                                \"date\" : date,\n",
    "                                \"slice_s_idx\": start_idx,\n",
    "                                \"slice_e_idx\": e_idx,\n",
    "                                #\"start_time\": str(selected_utc_time[i].values).split('T')[1], # more friendly time\n",
    "                                #\"end_time\": str(selected_utc_time[i+1].values).split('T')[1], # more friendly time\n",
    "                                \"ellipse_d_max\": spec_region.major_axis_length * pixel_resolution, ## d_max (equivalent ellipse)\n",
    "                                #\"ellipse_d_min\": spec_region.minor_axis_length * pixel_resolution, ## d_min (equivalent ellipse)\n",
    "                                \"Euclidean_d_max\": euclidean_dim * pixel_resolution,\n",
    "                                \"Feret_d_max\":spec_region.feret_diameter_max * pixel_resolution,\n",
    "                                \"area\": (spec_region.area * (pixel_resolution**2)),\n",
    "                                \"perimeter\": (spec_region.perimeter * pixel_resolution),\n",
    "                                \"circularity\": circularity_calc,\n",
    "                                \"probe\": probe,\n",
    "                                \"first_diode_trunc\": first_diode,\n",
    "                                \"last_diode_trunc\": last_diode,\n",
    "                                \"image_trunc\": image_trunc,\n",
    "                                \"aspect_ratio\": aspect_ratio_value  \n",
    "                                }\n",
    "\n",
    "                        filled_part = filled_part.astype(np.float32) ## convert to float 0 and 1s\n",
    "                        filled_part = np.expand_dims(filled_part, axis=-1) ## add extra dimention - this is for adding padding\n",
    "        \n",
    "                        imagex = tf.image.resize_with_crop_or_pad(filled_part, desired_image_size, desired_image_size)\n",
    "                        ## save image\n",
    "                        # Remove the extra dimension if needed\n",
    "                        image_np = imagex.numpy().squeeze()\n",
    "                        #plt.imshow(image_np, cmap='gray')\n",
    "                        plt.imsave(f'{save_loc}{particle_name}.png', image_np, cmap=\"gray\")\n",
    "                        \n",
    "\n",
    "        h5_file.close()\n",
    "        #print(one_particle_data)\n",
    "        one_particle_data_df = pd.DataFrame([one_particle_data])\n",
    "        particle_df = pd.concat([particle_df, one_particle_data_df], ignore_index=True)\n",
    "\n",
    "particle_df.to_csv(f'{save_loc}updated_duplicates_2nd.csv', index=False)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86825ccd-996e-4eeb-90de-d837242e2331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>slice_s_idx</th>\n",
       "      <th>slice_e_idx</th>\n",
       "      <th>ellipse_d_max</th>\n",
       "      <th>Euclidean_d_max</th>\n",
       "      <th>Feret_d_max</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>circularity</th>\n",
       "      <th>probe</th>\n",
       "      <th>first_diode_trunc</th>\n",
       "      <th>last_diode_trunc</th>\n",
       "      <th>image_trunc</th>\n",
       "      <th>aspect_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94298_2_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>94298</td>\n",
       "      <td>94314</td>\n",
       "      <td>146.839578</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>140.356688</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>313.137085</td>\n",
       "      <td>1.773399</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.089049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226470_4_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>226470</td>\n",
       "      <td>226486</td>\n",
       "      <td>174.590712</td>\n",
       "      <td>172.046505</td>\n",
       "      <td>186.010752</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>652.487373</td>\n",
       "      <td>2.606100</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230869_5_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>230869</td>\n",
       "      <td>230882</td>\n",
       "      <td>127.331888</td>\n",
       "      <td>116.619038</td>\n",
       "      <td>125.299641</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>403.847763</td>\n",
       "      <td>2.060084</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.422839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235921_7_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>235921</td>\n",
       "      <td>235929</td>\n",
       "      <td>101.879794</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>110.453610</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>216.568542</td>\n",
       "      <td>1.332978</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.968843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249985_2_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>249985</td>\n",
       "      <td>250005</td>\n",
       "      <td>253.887481</td>\n",
       "      <td>245.153013</td>\n",
       "      <td>259.615100</td>\n",
       "      <td>29400.0</td>\n",
       "      <td>1078.406204</td>\n",
       "      <td>3.147803</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>18539_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>18539</td>\n",
       "      <td>18598</td>\n",
       "      <td>579.097229</td>\n",
       "      <td>676.239603</td>\n",
       "      <td>688.186021</td>\n",
       "      <td>146400.0</td>\n",
       "      <td>2188.233765</td>\n",
       "      <td>2.602774</td>\n",
       "      <td>ch1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.589710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>34578_4_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>34578</td>\n",
       "      <td>34605</td>\n",
       "      <td>296.331342</td>\n",
       "      <td>342.052628</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>60400.0</td>\n",
       "      <td>1029.055916</td>\n",
       "      <td>1.395183</td>\n",
       "      <td>ch1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.090540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>34578_8_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>34578</td>\n",
       "      <td>34606</td>\n",
       "      <td>258.089121</td>\n",
       "      <td>259.615100</td>\n",
       "      <td>269.258240</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>519.350288</td>\n",
       "      <td>2.617562</td>\n",
       "      <td>ch1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.987685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>47102_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47136</td>\n",
       "      <td>333.023565</td>\n",
       "      <td>352.278299</td>\n",
       "      <td>363.593179</td>\n",
       "      <td>50100.0</td>\n",
       "      <td>1421.543289</td>\n",
       "      <td>3.209760</td>\n",
       "      <td>ch1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.378210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>47102_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47134</td>\n",
       "      <td>289.030963</td>\n",
       "      <td>318.904374</td>\n",
       "      <td>328.024389</td>\n",
       "      <td>50300.0</td>\n",
       "      <td>1128.761543</td>\n",
       "      <td>2.015703</td>\n",
       "      <td>ch1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name    date slice_s_idx slice_e_idx  ellipse_d_max  \\\n",
       "0     94298_2_19ch0  220719       94298       94314     146.839578   \n",
       "1    226470_4_19ch0  220719      226470      226486     174.590712   \n",
       "2    230869_5_19ch0  220719      230869      230882     127.331888   \n",
       "3    235921_7_19ch0  220719      235921      235929     101.879794   \n",
       "4    249985_2_19ch0  220719      249985      250005     253.887481   \n",
       "..              ...     ...         ...         ...            ...   \n",
       "150   18539_1_07ch1  220807       18539       18598     579.097229   \n",
       "151   34578_4_07ch1  220807       34578       34605     296.331342   \n",
       "152   34578_8_07ch1  220807       34578       34606     258.089121   \n",
       "153   47102_1_07ch1  220807       47102       47136     333.023565   \n",
       "154   47102_1_07ch1  220807       47102       47134     289.030963   \n",
       "\n",
       "     Euclidean_d_max  Feret_d_max      area    perimeter  circularity probe  \\\n",
       "0         130.000000   140.356688    4400.0   313.137085     1.773399   ch0   \n",
       "1         172.046505   186.010752   13000.0   652.487373     2.606100   ch0   \n",
       "2         116.619038   125.299641    6300.0   403.847763     2.060084   ch0   \n",
       "3         100.000000   110.453610    2800.0   216.568542     1.332978   ch0   \n",
       "4         245.153013   259.615100   29400.0  1078.406204     3.147803   ch0   \n",
       "..               ...          ...       ...          ...          ...   ...   \n",
       "150       676.239603   688.186021  146400.0  2188.233765     2.602774   ch1   \n",
       "151       342.052628   350.000000   60400.0  1029.055916     1.395183   ch1   \n",
       "152       259.615100   269.258240    8200.0   519.350288     2.617562   ch1   \n",
       "153       352.278299   363.593179   50100.0  1421.543289     3.209760   ch1   \n",
       "154       318.904374   328.024389   50300.0  1128.761543     2.015703   ch1   \n",
       "\n",
       "    first_diode_trunc last_diode_trunc image_trunc  aspect_ratio  \n",
       "0                   0                0           0      3.089049  \n",
       "1                   0                0           0      1.533949  \n",
       "2                   0                0           0      1.422839  \n",
       "3                   0                1           0      1.968843  \n",
       "4                   0                0           0      1.465888  \n",
       "..                ...              ...         ...           ...  \n",
       "150                 6                0           0      1.589710  \n",
       "151                 0               28           0      1.090540  \n",
       "152                 0               17           0      4.987685  \n",
       "153                21                0           0      1.378210  \n",
       "154                 0                0           0      1.172358  \n",
       "\n",
       "[155 rows x 15 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fe25bbd-e722-4893-a074-5c86f254eebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>slice_s_idx</th>\n",
       "      <th>slice_e_idx</th>\n",
       "      <th>ellipse_d_max</th>\n",
       "      <th>Euclidean_d_max</th>\n",
       "      <th>Feret_d_max</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>circularity</th>\n",
       "      <th>probe</th>\n",
       "      <th>first_diode_trunc</th>\n",
       "      <th>last_diode_trunc</th>\n",
       "      <th>image_trunc</th>\n",
       "      <th>aspect_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94298_2_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>94298</td>\n",
       "      <td>94311</td>\n",
       "      <td>146.839578</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>140.356688</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>313.137085</td>\n",
       "      <td>1.773399</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.089049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>230869_5_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>230869</td>\n",
       "      <td>230879</td>\n",
       "      <td>127.331888</td>\n",
       "      <td>116.619038</td>\n",
       "      <td>125.299641</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>403.847763</td>\n",
       "      <td>2.060084</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.422839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>249985_2_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>249985</td>\n",
       "      <td>250002</td>\n",
       "      <td>253.887481</td>\n",
       "      <td>245.153013</td>\n",
       "      <td>259.615100</td>\n",
       "      <td>29400.0</td>\n",
       "      <td>1078.406204</td>\n",
       "      <td>3.147803</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1403973_2_19ch0</td>\n",
       "      <td>220719</td>\n",
       "      <td>1403973</td>\n",
       "      <td>1403984</td>\n",
       "      <td>108.537894</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>230.710678</td>\n",
       "      <td>1.283546</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.349983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1016899_2_20ch0</td>\n",
       "      <td>220720</td>\n",
       "      <td>1016899</td>\n",
       "      <td>1016911</td>\n",
       "      <td>179.567816</td>\n",
       "      <td>180.277564</td>\n",
       "      <td>194.164878</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>657.989899</td>\n",
       "      <td>2.153320</td>\n",
       "      <td>ch0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.332239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>18539_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>18539</td>\n",
       "      <td>18595</td>\n",
       "      <td>473.767174</td>\n",
       "      <td>483.321839</td>\n",
       "      <td>493.963561</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>1509.533188</td>\n",
       "      <td>1.323594</td>\n",
       "      <td>ch1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.260946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>18539_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>18539</td>\n",
       "      <td>18595</td>\n",
       "      <td>579.097229</td>\n",
       "      <td>676.239603</td>\n",
       "      <td>688.186021</td>\n",
       "      <td>146400.0</td>\n",
       "      <td>2188.233765</td>\n",
       "      <td>2.602774</td>\n",
       "      <td>ch1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.589710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>34578_7_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>34578</td>\n",
       "      <td>34603</td>\n",
       "      <td>258.089121</td>\n",
       "      <td>259.615100</td>\n",
       "      <td>269.258240</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>519.350288</td>\n",
       "      <td>2.617562</td>\n",
       "      <td>ch1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.987685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>47102_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47131</td>\n",
       "      <td>317.255314</td>\n",
       "      <td>344.093011</td>\n",
       "      <td>355.105618</td>\n",
       "      <td>48600.0</td>\n",
       "      <td>1407.401154</td>\n",
       "      <td>3.243319</td>\n",
       "      <td>ch1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.307888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>47102_1_07ch1</td>\n",
       "      <td>220807</td>\n",
       "      <td>47102</td>\n",
       "      <td>47131</td>\n",
       "      <td>289.030963</td>\n",
       "      <td>318.904374</td>\n",
       "      <td>328.024389</td>\n",
       "      <td>50300.0</td>\n",
       "      <td>1128.761543</td>\n",
       "      <td>2.015703</td>\n",
       "      <td>ch1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name    date  slice_s_idx  slice_e_idx  ellipse_d_max  \\\n",
       "1      94298_2_19ch0  220719        94298        94311     146.839578   \n",
       "5     230869_5_19ch0  220719       230869       230879     127.331888   \n",
       "9     249985_2_19ch0  220719       249985       250002     253.887481   \n",
       "19   1403973_2_19ch0  220719      1403973      1403984     108.537894   \n",
       "31   1016899_2_20ch0  220720      1016899      1016911     179.567816   \n",
       "..               ...     ...          ...          ...            ...   \n",
       "301    18539_1_07ch1  220807        18539        18595     473.767174   \n",
       "302    18539_1_07ch1  220807        18539        18595     579.097229   \n",
       "306    34578_7_07ch1  220807        34578        34603     258.089121   \n",
       "307    47102_1_07ch1  220807        47102        47131     317.255314   \n",
       "308    47102_1_07ch1  220807        47102        47131     289.030963   \n",
       "\n",
       "     Euclidean_d_max  Feret_d_max      area    perimeter  circularity probe  \\\n",
       "1         130.000000   140.356688    4400.0   313.137085     1.773399   ch0   \n",
       "5         116.619038   125.299641    6300.0   403.847763     2.060084   ch0   \n",
       "9         245.153013   259.615100   29400.0  1078.406204     3.147803   ch0   \n",
       "19        110.000000   120.000000    3300.0   230.710678     1.283546   ch0   \n",
       "31        180.277564   194.164878   16000.0   657.989899     2.153320   ch0   \n",
       "..               ...          ...       ...          ...          ...   ...   \n",
       "301       483.321839   493.963561  137000.0  1509.533188     1.323594   ch1   \n",
       "302       676.239603   688.186021  146400.0  2188.233765     2.602774   ch1   \n",
       "306       259.615100   269.258240    8200.0   519.350288     2.617562   ch1   \n",
       "307       344.093011   355.105618   48600.0  1407.401154     3.243319   ch1   \n",
       "308       318.904374   328.024389   50300.0  1128.761543     2.015703   ch1   \n",
       "\n",
       "     first_diode_trunc  last_diode_trunc  image_trunc  aspect_ratio  \n",
       "1                    0                 0            0      3.089049  \n",
       "5                    0                 0            0      1.422839  \n",
       "9                    0                 0            0      1.465888  \n",
       "19                   0                 0            0      2.349983  \n",
       "31                   0                 0            0      1.332239  \n",
       "..                 ...               ...          ...           ...  \n",
       "301                  0                 0            0      1.260946  \n",
       "302                  6                 0            0      1.589710  \n",
       "306                  0                17            0      4.987685  \n",
       "307                 20                 0            0      1.307888  \n",
       "308                  0                 0            0      1.172358  \n",
       "\n",
       "[66 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dup_csv_pth = '/gws/nopw/j04/dcmex/users/ezriab/processed_stats/silly_duplicates/updated_duplicates_1st.csv'\n",
    "dup_df_2 = pd.read_csv(re_dup_csv_pth)\n",
    "\n",
    "full_duplicates_mask = dup_df_2.duplicated(subset=['name'])\n",
    "full_duplicates_df = dup_df_2[full_duplicates_mask]\n",
    "'''\n",
    "list_of_duplicates = list(full_duplicates_df['name'])\n",
    "double_duplicates_df = full_ds_stats[full_ds_stats['name'].isin(list_of_duplicates)]\n",
    "\n",
    "double_duplicates_df\n",
    "'''\n",
    "\n",
    "full_duplicates_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c587ad-9c52-4757-8822-7780818de259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
